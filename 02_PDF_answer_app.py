##### ê¸°ë³¸ ì •ë³´ ì…ë ¥ ##### 
## ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜: pip install streamlit PyPDF2 langchain deepl openai langchain-community tiktoken faiss-cpu  
## í”„ë¡œê·¸ë¨ ì‹¤í–‰: streamlit run 02_PDF_answer_app.py
# Streamlit íŒ¨í‚¤ì§€ ì¶”ê°€
import streamlit as st
# PDF reader
from PyPDF2 import PdfReader
# Langchain íŒ¨í‚¤ì§€ë“¤
from langchain_community.chat_models import ChatOpenAI
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from langchain.chains.question_answering import load_qa_chain
# deepl ë²ˆì—­ íŒ¨í‚¤ì§€ ì„¤ì¹˜ 
import deepl     

##### ê¸°ëŠ¥ êµ¬í˜„ í•¨ìˆ˜ #####

# ì˜ì–´ ë²ˆì—­
def deepl_trans(messages):
    auth_key = "3b9c5c42-29d9-4cc8-9289-ecf6bf01c2b7:fx" 
    translator = deepl.Translator(auth_key)

    try:
        result = translator.translate_text(messages, target_lang="KO")
        return result.text
    except deepl.exceptions.DeepLException as e:
        print(f"DeepL API ì˜¤ë¥˜ ë°œìƒ: {e}")
    except Exception as e:
        print(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")


##### ë©”ì¸ í•¨ìˆ˜ #####
def main():
    st.set_page_config(page_title="PDF analyzer", layout="wide")

    # ì‚¬ì´ë“œë°”
    with st.sidebar:

        # Open AI API í‚¤ ì…ë ¥ë°›ê¸°
        open_apikey = st.text_input(label='OPENAI API í‚¤', placeholder='Enter Your API Key', value='',type='password')
        
        # ì…ë ¥ë°›ì€ API í‚¤ í‘œì‹œ
        if open_apikey:
            st.session_state["OPENAI_API"] = open_apikey 
        st.markdown('---')
        
    # ë©”ì¸ê³µê°„
    st.header("PDF ë‚´ìš© ì§ˆë¬¸ í”„ë¡œê·¸ë¨ğŸ“œ")
    st.markdown('---')
    st.subheader("PDF íŒŒì¼ì„ ë„£ìœ¼ì„¸ìš”")
    # PDF íŒŒì¼ ë°›ê¸°
    pdf = st.file_uploader(" ", type="pdf")
    if pdf is not None:
        # PDF íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œí•˜ê¸°
        pdf_reader = PdfReader(pdf)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text()
        # ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ê¸°
        text_splitter = CharacterTextSplitter(
            separator="\n",
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len
        )
        chunks = text_splitter.split_text(text)

        st.markdown('---')
        st.subheader("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
        # ì‚¬ìš©ì ì§ˆë¬¸ ë°›ê¸°
        user_question = st.text_input("Ask a question about your PDF:")
        if user_question:
            # ì„ë² ë”©/ ì‹œë©˜í‹± ì¸ë±ìŠ¤
            embeddings = OpenAIEmbeddings(openai_api_key=st.session_state["OPENAI_API"])
            knowledge_base = FAISS.from_texts(chunks, embeddings)
            
            docs = knowledge_base.similarity_search(user_question)

            # ì§ˆë¬¸í•˜ê¸°
            llm = ChatOpenAI(temperature=0,
                    openai_api_key=st.session_state["OPENAI_API"],
                    max_tokens=2000,
                    model_name='gpt-3.5-turbo',
                    requesstt_timeout=120
                    )
            chain = load_qa_chain(llm, chain_type="stuff")
            response = chain.run(input_documents=docs, question=user_question)
            # ë‹µë³€ê²°ê³¼
            st.info(response)
            #í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ê¸°
            if st.button(label="ë²ˆì—­í•˜ê¸°"):
                trans = deepl_trans(response)
                st.success(trans)

if __name__=='__main__':
    main()