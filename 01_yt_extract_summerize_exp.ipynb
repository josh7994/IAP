{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유튜브 스크립트 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install langchain==0.3.26 # Version: 0.3.26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install langchain-community==0.3.27 # Version: 0.3.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain_community 패키지에서 YoutubeLoader를 임포트합니다.\n",
    "# 최신 버전의 LangChain에서는 이 경로를 사용하는 것이 좋습니다.\n",
    "from langchain_community.document_loaders import YoutubeLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install youtube_transcript_api==1.1.1 # Version: 1.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'Pn-W41hC764'}, page_content=\"I alluded in my opening remarks to the the jobs issue the economic effects on employment uh I think you have said uh in fact and I'm going to quote development of superhuman machine intelligence is probably the greatest threat to the continued existence of humanity end quote you may have had in mind the effect on on jobs which is really my biggest nightmare in the long term uh let me ask you uh what your biggest nightmare is and whether you share that concern like with all technological revolutions I expect there to be significant impact on jobs but exactly what that impact looks like is very difficult to predict if we went back to the the other side of a previous technological Revolution talking about the jobs that exist on the other side um you know you can go back and read books of this it's what people said at the time it's difficult I believe that there will be far greater jobs on the other side of this and the jobs of today will get better I think it's important first of all I think it's important to understand and think about gpd4 as a tool not a creature which is easy to get confused and it's a tool that people have a great deal of control over and how they use it and second gpt4 and things other systems like it are good at doing tasks not jobs and so you see already people that are using gpt4 to do their job much more efficiently by helping them with tasks now gbt4 will I think entirely automate away some jobs and it will create new ones that we believe will be much better this happens again my understanding of the history of technology is one long technological Revolution not a bunch of different ones put together but this has been continually happening we as our quality of life raises and as machines and tools that we create can help us live better lives uh the bar raises for what we do and and our human ability and what we spend our time going after uh goes after more ambitious more satisfying projects so there there will be an impact on jobs we try to be very clear about that and I think it will require partnership between the industry and government but mostly action by government to figure out how we want to mitigate that but I'm very optimistic about how great the jobs of the future will be thank you let me ask Ms Montgomery and Professor Marcus for your reactions those questions as well Ms Montgomery on the jobs Point yeah I mean well it's a hugely important question um and it's one that we've been talking about for a really long time at IBM you know we do believe that Ai and we've said it for a long time is going to change every job new jobs will be created many more jobs will be transformed and some jobs will transition away I'm a personal example of a job that didn't exist when I joined IBM and I have a team of AI governance professionals who are in new roles that we created you know as early as three years ago I mean they're new and they're growing so I think the most important thing that we could be doing and Canon should be doing now is to prepare the workforce of today and the workforce of tomorrow for partnering with F AI Technologies and using them and we've been very involved for for years now in doing that in focusing on skills-based hiring in educating for the skills of the future our skills build platform has seven million Learners and over a thousand courses worldwide focused on skills and we've pledged to train 30 million individuals by 2030 in the skills that are needed for society today thank you Professor Marcus may I go back to the first question as well absolutely on on the subject of nutrition labels I think we absolutely need to do that I think that there's some technical challenges in that building proper nutrition labels goes hand in hand with transparency the biggest scientific challenge in understanding these models is how they generalize what do they memorize and what new things do they do the more that there's in the data set for example the thing that you want to test accuracy on the less you can get a proper read on that so it's important first of all that scientists be part of that process and second that we have much greater transparency about what actually goes into these systems if we don't know what's in them then we don't know exactly how well they're doing when we give something new and we don't know how good a benchmark that will be for something that's entirely novel so I could go into that more but I want to flag that second is on jobs past performance history is not a guarantee of the future it has always been the case in the past that we have had more jobs that new jobs new professions come in as new technologies come in I think this one's going to be different and the real question is over what time time scale is it going to be 10 years is it going to be 100 years and I don't think anybody knows the answer to that question I think in the long run so-called artificial general intelligence really will replace a large fraction of human jobs we're not that close to artificial general intelligence despite all of the media hype and so forth I would say that what we have right now is just small sampling of the AI that we will build in 20 years people will laugh at this as I think it was Senator Hawley made the but maybe Senator Durbin made the example about this it was Senator Durbin made the example about cell phones when we look back at the AI of today 20 years ago we'll be like wow that stuff was really unreliable it couldn't really do planning which is an important technical aspect it's reasoning wasability and reasoning abilities were limited but when we get to AGI or artificial general intelligence mainly let's say it's 50 years that really is going to have I think profound effects on labor and there's just no way around that and last I don't know if I'm allowed to do this but I will note that Sam's worst fear I do not think is employment and he never told us what his worst fear actually is and I think it's germane to find out thank you I'm going to ask Mr Altman if he cares to respond yeah look we have tried to be very clear about the magnitude of the risks here I I think jobs and employment and what we're all going to do with our time really matters I agree that when we get to very powerful systems the landscape will change I think I'm just more optimistic that we are incredibly creative and we find new things to do with better tools and that will keep happening um my worst fears are that we cause significant we the field the technology the industry cause significant harm to the world I think that could happen a lot of different ways it's why we started the company it's a big part of why I'm here today and why we've been here in the past and we've been able to spend some time with you I think if this technology goes wrong it can go quite wrong and we want to be vocal about that we want to work with the government to prevent that from happening but we we try to be very clear-eyed about what the downside case is and the work that we have to do to mitigate that thank you and\")]\n"
     ]
    }
   ],
   "source": [
    "# YouTube 동영상 URL을 지정하여 YoutubeLoader를 초기화합니다.\n",
    "# add_video_info=False 옵션은 동영상 메타데이터(제목, 썸네일 등)를\n",
    "# 최종 문서에 포함하지 않고 자막 텍스트만 가져오도록 설정합니다.\n",
    "loader = YoutubeLoader.from_youtube_url(\n",
    "    \"https://www.youtube.com/watch?v=Pn-W41hC764\",\n",
    "    add_video_info=False\n",
    ")\n",
    "\n",
    "# loader.load() 메서드를 호출하여 동영상의 자막을 문서 형태로 불러옵니다.\n",
    "# 각 문서는 페이지 내용(자막 텍스트)과 메타데이터(선택적)를 포함합니다.\n",
    "transcript = loader.load()\n",
    "\n",
    "# 불러온 자막 문서(transcript)를 출력합니다.\n",
    "# 결과는 Document 객체의 리스트 형태입니다.\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 긴 내용 요약하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 코드는 불러온 자막을 요약하는 예제입니다.\n",
    "# 먼저, 자막을 요약하기 위해 필요한 모듈들을 임포트합니다\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 쪼개기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RecursiveCharacterTextSplitter를 사용하여 긴 문서를 분할합니다.\n",
    "# chunk_size: 각 문서 청크의 최대 문자 수\n",
    "# chunk_overlap: 청크 간 겹치는 문자 수\n",
    "# 이 설정은 긴 자막을 처리하기 위해 적절한 크기로 나누는 데 사용됩니다.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=0)\n",
    "text = text_splitter.split_documents(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'Pn-W41hC764'}, page_content=\"I alluded in my opening remarks to the the jobs issue the economic effects on employment uh I think you have said uh in fact and I'm going to quote development of superhuman machine intelligence is probably the greatest threat to the continued existence of humanity end quote you may have had in mind the effect on on jobs which is really my biggest nightmare in the long term uh let me ask you uh what your biggest nightmare is and whether you share that concern like with all technological revolutions I expect there to be significant impact on jobs but exactly what that impact looks like is very difficult to predict if we went back to the the other side of a previous technological Revolution talking about the jobs that exist on the other side um you know you can go back and read books of this it's what people said at the time it's difficult I believe that there will be far greater jobs on the other side of this and the jobs of today will get better I think it's important first of all I think it's important to understand and think about gpd4 as a tool not a creature which is easy to get confused and it's a tool that people have a great deal of control over and how they use it and second gpt4 and things other systems like it are good at doing tasks not jobs and so you see already people that are using gpt4 to do their job much more efficiently by helping them with tasks now gbt4 will I think entirely automate away some jobs and it will create new ones that we believe will be much better this happens again my understanding of the history of technology is one long technological Revolution not a bunch of different ones put together but this has been continually happening we as our quality of life raises and as machines and tools that we create can help us live better lives uh the bar raises for what we do and and our human ability and what we spend our time going after uh goes after more ambitious more satisfying projects so there there will be an impact on jobs we try to be very clear about that and I think it will require partnership between the industry and government but mostly action by government to figure out how we want to mitigate that but I'm very optimistic about how great the jobs of the future will be thank you let me ask Ms Montgomery and Professor Marcus for your reactions those questions as well Ms Montgomery on the jobs Point yeah I mean well it's a hugely important question um and it's one that we've been talking about for a really long time at IBM you know we do believe that Ai and we've said it for a long time is going to change every job new jobs will be created many more jobs will be transformed and some jobs will transition away I'm a personal example of a job that didn't exist when I joined IBM and I have a team of AI governance professionals who are in new roles that we created you know as early as three years ago I mean they're new and they're growing so I think the most important thing that we could be doing and Canon should be doing now is to prepare the workforce of today and the workforce of tomorrow for partnering with F AI Technologies and using them and we've been very involved for for years now in doing that in focusing on skills-based hiring in educating for the skills of the future our skills build platform has seven million Learners and over a thousand courses worldwide focused on skills and we've pledged to train 30 million individuals by 2030 in the skills that are needed for society today thank you Professor Marcus may I go back to the first question as well absolutely on on the subject of nutrition labels I think we absolutely need to do that I think that there's some technical challenges in that building proper nutrition labels goes hand in hand with transparency the biggest scientific challenge in understanding these models is how they generalize what do they memorize and what new things do they do the more that there's in the data set for example the thing that you want to test accuracy on\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'Pn-W41hC764'}, page_content=\"the less you can get a proper read on that so it's important first of all that scientists be part of that process and second that we have much greater transparency about what actually goes into these systems if we don't know what's in them then we don't know exactly how well they're doing when we give something new and we don't know how good a benchmark that will be for something that's entirely novel so I could go into that more but I want to flag that second is on jobs past performance history is not a guarantee of the future it has always been the case in the past that we have had more jobs that new jobs new professions come in as new technologies come in I think this one's going to be different and the real question is over what time time scale is it going to be 10 years is it going to be 100 years and I don't think anybody knows the answer to that question I think in the long run so-called artificial general intelligence really will replace a large fraction of human jobs we're not that close to artificial general intelligence despite all of the media hype and so forth I would say that what we have right now is just small sampling of the AI that we will build in 20 years people will laugh at this as I think it was Senator Hawley made the but maybe Senator Durbin made the example about this it was Senator Durbin made the example about cell phones when we look back at the AI of today 20 years ago we'll be like wow that stuff was really unreliable it couldn't really do planning which is an important technical aspect it's reasoning wasability and reasoning abilities were limited but when we get to AGI or artificial general intelligence mainly let's say it's 50 years that really is going to have I think profound effects on labor and there's just no way around that and last I don't know if I'm allowed to do this but I will note that Sam's worst fear I do not think is employment and he never told us what his worst fear actually is and I think it's germane to find out thank you I'm going to ask Mr Altman if he cares to respond yeah look we have tried to be very clear about the magnitude of the risks here I I think jobs and employment and what we're all going to do with our time really matters I agree that when we get to very powerful systems the landscape will change I think I'm just more optimistic that we are incredibly creative and we find new things to do with better tools and that will keep happening um my worst fears are that we cause significant we the field the technology the industry cause significant harm to the world I think that could happen a lot of different ways it's why we started the company it's a big part of why I'm here today and why we've been here in the past and we've been able to spend some time with you I think if this technology goes wrong it can go quite wrong and we want to be vocal about that we want to work with the government to prevent that from happening but we we try to be very clear-eyed about what the downside case is and the work that we have to do to mitigate that thank you and\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용할 LLM 모델 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install openai\n",
    "\n",
    "pip install tiktoken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AI-RPA사업단\\AppData\\Local\\Temp\\ipykernel_45960\\81286624.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    # temperature: 창의성을 제어하는 매개변수입니다.\n",
    "    # 0에 가까울수록 보수적이고 일관된 답변을 생성하며,\n",
    "    # 1에 가까울수록 다양하고 창의적인 답변을 생성합니다.\n",
    "    # 여기서는 0으로 설정하여 일관된 답변을 유도합니다.\n",
    "    temperature=0,\n",
    "\n",
    "    # openai_api_key: OpenAI API를 사용하기 위한 인증 키입니다.\n",
    "    # 이 키를 통해 사용자 계정이 인증됩니다. 보안을 위해 환경 변수를 사용하는 것이 권장됩니다.\n",
    "    openai_api_key=\"\",\n",
    "\n",
    "    # max_tokens: 모델이 생성할 수 있는 답변의 최대 토큰(단어 조각) 수입니다.\n",
    "    # 이 값을 너무 낮게 설정하면 답변이 중간에 잘릴 수 있습니다.\n",
    "    max_tokens=3000,\n",
    "\n",
    "    # model_name: 사용할 LLM 모델의 이름을 지정합니다.\n",
    "    # 'gpt-3.5-turbo'는 OpenAI의 최신 GPT-3.5 모델로, 빠른 속도와 합리적인 비용이 특징입니다.\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "\n",
    "    # request_timeout: API 요청에 대한 응답을 기다리는 최대 시간(초)입니다.\n",
    "    # 네트워크 지연 등으로 인해 요청이 실패하는 것을 방지하기 위해 설정합니다.\n",
    "    request_timeout=120\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요약에 사용할 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각각의 chunk(문서 덩어리)를 요약하기 위한 프롬프트 템플릿입니다.\n",
    "# 이 프롬프트는 'Map-Reduce' 방식에서 'Map' 단계에 사용됩니다.\n",
    "# 각 덩어리가 LLM에 전달될 때, 이 템플릿에 맞게 프롬프트가 구성됩니다.\n",
    "prompt = PromptTemplate(\n",
    "    # template: LLM에게 어떤 작업을 지시할지 정의하는 문자열입니다.\n",
    "    # {text}라는 변수는 각 문서 덩어리의 내용으로 대체됩니다.\n",
    "    template=\"\"\"Summarize the youtube video whose transcript is provided within backticks \\\n",
    "    ```{text}```\n",
    "    \"\"\",\n",
    "    # input_variables: 템플릿에 사용될 변수명을 리스트로 지정합니다.\n",
    "    # 여기서는 'text' 변수가 문서 덩어리의 내용을 받습니다.\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "# 요약된 내용들을 취합하여 다시 한번 요약하기 위한 프롬프트 템플릿입니다.\n",
    "# 이 프롬프트는 'Map-Reduce' 방식에서 'Reduce' 단계에 사용됩니다.\n",
    "# 'Map' 단계에서 요약된 모든 내용들을 하나로 합친 후, 이 템플릿을 사용하여 최종 요약을 생성합니다.\n",
    "combine_prompt = PromptTemplate(\n",
    "    # template: 최종 요약을 위한 지시사항을 포함합니다.\n",
    "    # 모든 중간 요약 내용이 {text} 변수에 합쳐져 들어갑니다.\n",
    "    # \"8 to 10 sentences\"라는 지시를 통해 최종 요약의 길이를 제어합니다.\n",
    "    template=\"\"\"Combine all the youtube video transcripts  provided within backticks \\\n",
    "    ```{text}```\n",
    "    Provide a concise summary between 8 to 10 sentences.\n",
    "    \"\"\",\n",
    "    # input_variables: 'text' 변수에 중간 요약들이 결합되어 들어갑니다.\n",
    "    input_variables=[\"text\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요약 시작하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_summarize_chain 함수를 사용하여 요약 체인을 생성합니다.\n",
    "chain = load_summarize_chain(\n",
    "    # llm: 요약에 사용할 언어 모델(LLM) 인스턴스를 지정합니다.\n",
    "    # 이전에 ChatOpenAI로 초기화한 llm 객체가 여기에 들어갑니다.\n",
    "    llm,\n",
    "    \n",
    "    # chain_type: 요약 방식을 결정합니다. \"map_reduce\"는 큰 문서를 처리하는 데 효과적인 전략입니다.\n",
    "    # 1. \"map\" 단계: 큰 문서를 여러 조각(chunk)으로 나누고, 각각의 조각을 개별적으로 요약합니다.\n",
    "    # 2. \"reduce\" 단계: \"map\" 단계에서 생성된 모든 개별 요약들을 하나로 합쳐 최종 요약을 만듭니다.\n",
    "    chain_type=\"map_reduce\",\n",
    "    \n",
    "    # verbose: 체인의 실행 과정을 상세히 출력할지 여부를 결정합니다.\n",
    "    # False로 설정하면, 내부적으로 어떤 프롬프트가 사용되고 어떤 단계가 진행되는지 출력하지 않습니다.\n",
    "    # 디버깅 시에는 True로 설정하는 것이 유용합니다.\n",
    "    verbose=False,\n",
    "    \n",
    "    # map_prompt: \"map\" 단계에서 각 문서 조각에 적용할 프롬프트 템플릿을 지정합니다.\n",
    "    # 이 템플릿에 따라 각 문서 조각이 개별적으로 요약됩니다.\n",
    "    map_prompt=prompt,\n",
    "    \n",
    "    # combine_prompt: \"reduce\" 단계에서 모든 개별 요약을 합칠 때 사용할 프롬프트 템플릿을 지정합니다.\n",
    "    # 이 템플릿을 통해 최종 요약의 형식과 길이를 제어할 수 있습니다.\n",
    "    combine_prompt=combine_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AI-RPA사업단\\AppData\\Local\\Temp\\ipykernel_45960\\623866027.py:10: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  output = chain.run(text)\n"
     ]
    }
   ],
   "source": [
    "# chain.run() 메서드를 사용하여 요약 체인을 실행합니다.\n",
    "# 이 메서드는 LangChain 체인의 가장 간단한 실행 방식입니다.\n",
    "# `text` 변수는 Document 객체 리스트이며,\n",
    "# 이는 `load_summarize_chain` 함수에 정의된 대로\n",
    "# 체인의 입력으로 사용됩니다.\n",
    "# chain_type이 \"map_reduce\"로 설정되어 있으므로,\n",
    "# 이 메서드는 내부적으로 다음 두 단계를 실행합니다.\n",
    "# 1. Map 단계: 각 문서 청크(`text`의 요소)를 개별적으로 요약합니다.\n",
    "# 2. Reduce 단계: 모든 개별 요약을 합쳐 최종 요약을 생성합니다.\n",
    "output = chain.run(text)\n",
    "\n",
    "# 최종적으로 생성된 요약 결과가 `output` 변수에 저장됩니다.\n",
    "# 이 변수는 요약된 텍스트를 포함하는 문자열입니다.\n",
    "# 사용자는 이 변수를 출력하거나, 파일에 저장하는 등 다양한 용도로 활용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The video discusses the impact of superhuman machine intelligence on jobs and the economy, with the speakers believing that while some jobs may be automated away, new and better jobs will be created. They stress the importance of preparing the workforce to partner with AI technologies and the need for transparency and proper nutrition labels in AI models. Scientists are highlighted as crucial in the development of AI systems, with an emphasis on understanding how these systems work. The potential impact of artificial general intelligence on future job prospects is also mentioned, with concerns about potential harm from AI technology. However, there is optimism expressed about human creativity and adaptability in finding new opportunities with advanced tools. Both speakers emphasize the importance of being aware of the risks associated with AI technology and working towards mitigating them.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 번역하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deepl을 활용하여 번역하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install deepl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 동영상에서는 초인적인 기계 지능이 일자리와 경제에 미치는 영향에 대해 논의하며, 일부 일자리는 자동화로 사라질 수 있지만 새롭고 더 나은 일자리가 창출될 것이라고 전망합니다. 이들은 AI 기술과 협력할 인력을 준비하는 것의 중요성과 AI 모델의 투명성 및 적절한 영양 표시의 필요성을 강조합니다. 과학자들은 AI 시스템 개발에 있어 과학자들의 역할이 매우 중요하며, 이러한 시스템의 작동 방식을 이해하는 데 중점을 두고 있습니다. 인공 일반 지능이 미래의 직업 전망에 미칠 잠재적 영향에 대해서도 언급되며, AI 기술로 인한 잠재적 피해에 대한 우려도 제기됩니다. 그러나 첨단 도구를 통해 새로운 기회를 찾는 인간의 창의성과 적응력에 대한 낙관론도 제기됩니다. 두 연사 모두 AI 기술과 관련된 위험을 인식하고 이를 완화하기 위해 노력하는 것이 중요하다고 강조합니다.\n"
     ]
    }
   ],
   "source": [
    "# TODO: 실제 DeepL API 인증 키로 교체하세요.\n",
    "auth_key = \"3b9c5c42-29d9-4cc8-9289-ecf6bf01c2b7:fx\" \n",
    "translator = deepl.Translator(auth_key)\n",
    "\n",
    "try:\n",
    "    result = translator.translate_text(output, target_lang=\"KO\")\n",
    "    print(result.text)\n",
    "except deepl.exceptions.DeepLException as e:\n",
    "    print(f\"DeepL API 오류 발생: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"예상치 못한 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "W06_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
